{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sewar.full_ref import mse, rmse, psnr, rmse_sw, uqi, ssim, ergas, scc, rase, sam, msssim, vifp, psnrb \n",
    "metrics = {'mse':mse, 'rmse':rmse, 'psnr':psnr, 'rmse_sw':rmse_sw, 'uqi':uqi, 'ssim':ssim, \n",
    "    'ergas':ergas, 'scc':scc, 'rase':rase, 'sam': sam, 'msssim': msssim, 'vifp':vifp, 'psnrb':psnrb }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract images from video in Python\n",
    "\n",
    "https://www.geeksforgeeks.org/extract-images-from-video-in-python/\n",
    "\n",
    "OpenCV - Getting Started with Videos\n",
    "\n",
    "https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(frame, idx):\n",
    "    name = './data/frame' + str(idx) + '.jpg'\n",
    "    cv2.imwrite(name, frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving images with thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"Introduction\"\n",
    "\n",
    "MSE_SAME = 0.1\n",
    "# MSE_SAME = 0.0001\n",
    "MSE_NEW = 4.4\n",
    "MSE_VALID = 6\n",
    "MSSSIM_SAME = 0.999\n",
    "WHITE_FRAME = 528765071 \n",
    "FRAME_STEP = 10\n",
    "\n",
    "video_path = '/mnt/c/Users/Eduardo/Downloads/' + video_name + '.mp4'\n",
    "cam = cv2.VideoCapture(video_path)\n",
    "_, last_frame = cam.read()\n",
    "last_frame_gray = cv2.cvtColor(last_frame, cv2.COLOR_BGR2GRAY)\n",
    "last_image_gray = last_frame_gray\n",
    "\n",
    "currentframe = 0\n",
    "white_check = np.sum(last_frame_gray)\n",
    "\n",
    "if(white_check >= WHITE_FRAME):\n",
    "    print(f'X Image{currentframe} -> white')\n",
    "else:\n",
    "    print(f'X Image{currentframe} -> {white_check} white')\n",
    "    save_image(last_frame, currentframe)\n",
    "    \n",
    "currentframe += 1\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    for  _ in range(FRAME_STEP):\n",
    "        ret, frame = cam.read()\n",
    "        currentframe += 1\n",
    "  \n",
    "    if ret:\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        similarity = mse(last_frame_gray, frame_gray)\n",
    "\n",
    "        if(similarity < MSE_SAME):\n",
    "            newimg_thresh = mse(frame_gray, last_image_gray)\n",
    "\n",
    "            if(newimg_thresh > MSE_NEW):\n",
    "                valid_image = True\n",
    "\n",
    "                if(newimg_thresh < MSE_VALID):\n",
    "                    double_check = msssim(frame_gray, last_image_gray)\n",
    "                    if(double_check > MSSSIM_SAME):\n",
    "                        print(f'X Image{currentframe} -> {double_check} msssim')\n",
    "                        valid_image = False\n",
    "                \n",
    "                if(valid_image):\n",
    "                    white_check = np.sum(frame_gray)\n",
    "                    if(white_check >= WHITE_FRAME):\n",
    "                        print(f'X Image{currentframe} -> white')\n",
    "                        valid_image = False\n",
    "\n",
    "                if(valid_image):\n",
    "                    white_check = np.sum(frame_gray)\n",
    "                    save_image(frame, currentframe)\n",
    "                    print(f'Image{currentframe} -> {newimg_thresh}, {white_check}')\n",
    "                \n",
    "                last_image_gray = frame_gray\n",
    "                    \n",
    "        last_frame_gray = frame_gray\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Video: What kinds of problems can it solve_.mp4\n",
    "* Frame: 4500 (same)\n",
    "    * mse: 5.704356\t\n",
    "    * msssim: 0.999670\n",
    "* Frame: 8358 (little diff)\n",
    "    * mse: 4.548090\n",
    "    * msssim: 0.997047\n",
    "\n",
    "Results research\n",
    "* same_image -> msssim = 1, msssim >= 0.999670\n",
    "* min_change -> 0.997047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"What kinds of problems can it solve_.mp4\"\n",
    "imgs_idx = [0, 167, 511, 1309, 1383, 1590, 1791, 1896, 2791, 3502, 4466, 4500, 5045, 5978, 6754, 7397, 8035, 8358, 8668, 8866]\n",
    "# test_metrics = ['mse', 'rmse', 'psnr', 'uqi', 'ergas', 'scc', 'rase', 'sam', 'msssim', 'vifp', 'psnrb']\n",
    "test_metrics = ['ssim']\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "_, last_frame = cam.read()\n",
    "last_image = last_frame\n",
    "currentframe = 1\n",
    "\n",
    "data = {'img': imgs_idx[1:]}\n",
    "\n",
    "for metric in test_metrics:\n",
    "    data[metric] = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_image_gray = cv2.cvtColor(last_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            for metric in test_metrics:\n",
    "                if metric == 'msssim':\n",
    "                    data[metric].append(metrics[metric](frame_gray, last_image_gray).real)\n",
    "                else:\n",
    "                    data[metric].append(metrics[metric](frame_gray, last_image_gray))\n",
    "            \n",
    "            last_image = frame\n",
    "            \n",
    "        currentframe += 1\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"Course introduction.mp4\"\n",
    "imgs_idx = [0, 139, 267, 314, 459, 585, 713, 794, 938, 1500]\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "_, last_frame = cam.read()\n",
    "last_image = last_frame\n",
    "currentframe = 1\n",
    "\n",
    "sim_mse = []\n",
    "newimg_mse = []\n",
    "sim_msssim = []\n",
    "newimg_msssim = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_frame_gray = cv2.cvtColor(last_frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_image_gray = cv2.cvtColor(last_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # sim_mse.append(mse(last_frame_gray, frame_gray))\n",
    "            # newimg_mse.append(mse(frame_gray, last_image_gray))\n",
    "            sim_msssim.append(msssim(last_frame_gray, frame_gray).real)\n",
    "            newimg_msssim.append(msssim(frame_gray, last_image_gray).real)\n",
    "            \n",
    "            last_image = frame\n",
    "            \n",
    "        currentframe += 1\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'img': imgs_idx[1:],\n",
    "    # 'sim_mse': sim_mse,\n",
    "    # 'newimg_mse': newimg_mse,\n",
    "    'sim_msssim': sim_msssim,\n",
    "    'newimg_msssim': newimg_msssim\n",
    "})\n",
    "\n",
    "cam.release()\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing two pairs of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(video_name)\n",
    "\n",
    "imgs_idx = [4438, 4500, 8035, 8358]\n",
    "imgs = {}\n",
    "currentframe = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            imgs[currentframe] = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        currentframe += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp1_2 = []\n",
    "comp3_4 = []\n",
    "\n",
    "for metr in metrics:\n",
    "    comp1_2.append(metr(imgs[imgs_idx[0]], imgs[imgs_idx[1]]))\n",
    "    comp3_4.append(metr(imgs[imgs_idx[2]], imgs[imgs_idx[3]]))\n",
    "\n",
    "data = pd.DataFrame({'metric': metrics.keys(), 'comp1_2': comp1_2, 'comp3_4':comp3_4})\n",
    "data['good'] = data['comp1_2'] > data['comp3_4']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frames similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(\"Course introduction.mp4\")\n",
    "_, last_frame = cam.read()\n",
    "\n",
    "similarity_all = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        similarity_all.append(mse(last_frame, frame))\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev_tf211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "032a79404451c8e544ed63ad22a7b921b77b02e0977aab28375371efbf6895a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
