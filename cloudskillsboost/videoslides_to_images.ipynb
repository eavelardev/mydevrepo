{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sewar.full_ref import mse, rmse, psnr, rmse_sw, uqi, ssim, ergas, scc, rase, sam, msssim, vifp, psnrb \n",
    "metrics = {'mse':mse, 'rmse':rmse, 'psnr':psnr, 'rmse_sw':rmse_sw, 'uqi':uqi, 'ssim':ssim, \n",
    "    'ergas':ergas, 'scc':scc, 'rase':rase, 'sam': sam, 'msssim': msssim, 'vifp':vifp, 'psnrb':psnrb }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract images from video in Python\n",
    "\n",
    "https://www.geeksforgeeks.org/extract-images-from-video-in-python/\n",
    "\n",
    "OpenCV - Getting Started with Videos\n",
    "\n",
    "https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(video_name, frame, slide, num_frame):\n",
    "    name = f'./data/{video_name}/frame{slide}-{num_frame}.jpg'\n",
    "    cv2.imwrite(name, frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving images with thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training at scale with Vertex AI\n",
      "\n",
      "Image1-31 -> 1290.69, 488118736\n",
      "X Image2-166-> 5.34, 0.999331 msssim\n",
      "Image2-751 -> 3025.34, 520781512\n",
      "Image3-1252 -> 2632.94, 496933249\n",
      "X Image4-1288-> 4.68, 0.999251 msssim\n",
      "X Image4-1447-> 6.06, 0.999042 msssim\n",
      "X Image4-1606-> 5.06, 0.999128 msssim\n",
      "X Image4-1768-> 4.65, 0.999138 msssim\n",
      "X Image4-1927-> 4.55, 0.999438 msssim\n",
      "Image4-2209 -> 2698.34, 515836264\n",
      "Image5-2692 -> 1870.74, 510891660\n",
      "Image6-2884 -> 1479.46, 524411925\n",
      "Image7-2968 -> 95.08, 523079611\n",
      "Image8-3049 -> 104.22, 521614524\n",
      "Image9-3160 -> 121.86, 519915275\n",
      "Image10-3295 -> 1455.66, 517955133\n",
      "Image11-3565 -> 73.66, 516497988\n",
      "Image12-3670 -> 1373.73, 517577173\n",
      "Image13-3799 -> 2570.63, 499083797\n",
      "X Image14-3847-> 5.11, 0.999356 msssim\n",
      "X Image14-4006-> 4.54, 0.999532 msssim\n",
      "X Image14-4486-> 4.28, 0.999558 msssim\n",
      "X Image14-5125-> 4.23, 0.999552 msssim\n",
      "X Image14-5605-> 4.26, 0.999575 msssim\n",
      "Image14-5953 -> 2816.76, 501426177\n",
      "X Image15-6088-> 6.61, 0.999456 msssim\n",
      "Image15-6406 -> 2132.64, 508562071\n",
      "Image16-6541 -> 199.24, 508760734\n",
      "X Image17-6727-> 4.00, 0.999650 msssim\n",
      "Image17-7330 -> 1459.56, 500413285\n",
      "X Image18-7366-> 4.36, 0.999590 msssim\n",
      "X Image18-7528-> 4.08, 0.999601 msssim\n",
      "Image18-7600 -> 2256.17, 502908427\n",
      "X Image19-7687-> 4.14, 0.999622 msssim\n",
      "Image19-8422 -> 2348.39, 511448746\n",
      "Image20-8875 -> 2080.99, 512685675\n",
      "Image21-9385 -> 1552.43, 506735173\n",
      "Image22-10102 -> 2063.74, 511276962\n",
      "X Image23-10246-> 4.89, 0.999676 msssim\n"
     ]
    }
   ],
   "source": [
    "videos_name = [\n",
    "    # 'Introduction',\n",
    "    'Training at scale with Vertex AI',\n",
    "    # 'Lab intro_ Training at scale with the Vertex AI Training Service'\n",
    "]\n",
    "\n",
    "MSE_SAME = 0.07 # 0.07 - 0.1\n",
    "SAMPLING_RATE = 0.1 # 0.05 - 0.14 seconds\n",
    "SAMPLING_CHK_TIME = 0.6\n",
    "\n",
    "MSE_NEW = 4\n",
    "MSE_VALID = 15.53\n",
    "MSSSIM_SAME = 0.998038\n",
    "# MSSSIM_SAME = 0.997781\n",
    "WHITE_FRAME = 528757248\n",
    "BLACK_FRAME = 2339\n",
    "\n",
    "def is_static(val):\n",
    "    return val < MSE_SAME\n",
    "\n",
    "\n",
    "def check_bw_frame(frame, idx):\n",
    "    bw_check = np.sum(frame)\n",
    "    valid_frame = True\n",
    "\n",
    "    if(bw_check >= WHITE_FRAME):\n",
    "        print(f'X Image{idx} -> white')\n",
    "        valid_frame = False\n",
    "    elif(bw_check <= BLACK_FRAME):\n",
    "        print(f'X Image{idx} -> black')\n",
    "        valid_frame = False\n",
    "\n",
    "    return valid_frame, bw_check\n",
    "\n",
    "\n",
    "for video_name in videos_name:\n",
    "\n",
    "    print(f'\\n{video_name}\\n')\n",
    "\n",
    "    if not os.path.exists(f'data/{video_name}'):\n",
    "        os.makedirs(f'data/{video_name}')\n",
    "    \n",
    "    video_path = f'/mnt/c/Users/Eduardo/Downloads/{video_name}.mp4'\n",
    "    cam = cv2.VideoCapture(video_path)\n",
    "\n",
    "    currentframe = 0\n",
    "    num_slide = 1\n",
    "\n",
    "    #### Check if video start static\n",
    "    _, frame = cam.read()\n",
    "    currentframe += 1\n",
    "    last_frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    last_image_gray = last_frame_gray\n",
    "\n",
    "    static_found = False\n",
    "\n",
    "    frame_step = round(SAMPLING_RATE * cam.get(cv2.CAP_PROP_FPS))\n",
    "    num_frames_chk = round(SAMPLING_CHK_TIME * cam.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    while((static_found == False) and (currentframe < num_frames_chk)):\n",
    "        for  _ in range(frame_step):\n",
    "            ret, frame = cam.read()\n",
    "            currentframe += 1\n",
    "\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        similarity = mse(frame_gray, last_frame_gray)\n",
    "\n",
    "        if(is_static(similarity)):\n",
    "            valid_image, bw = check_bw_frame(last_image_gray, currentframe)\n",
    "\n",
    "            if(valid_image):\n",
    "                print(f'Image{currentframe} -> {bw}')\n",
    "                save_image(video_name, frame, num_slide, currentframe)\n",
    "                num_slide += 1\n",
    "\n",
    "            static_found = True\n",
    "\n",
    "        last_frame_gray = frame_gray\n",
    "        last_image_gray = frame_gray\n",
    "        \n",
    "    #### end\n",
    "\n",
    "    while(True):\n",
    "        \n",
    "        for  _ in range(frame_step):\n",
    "            ret, frame = cam.read()\n",
    "            currentframe += 1\n",
    "    \n",
    "        if ret:\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            similarity = mse(last_frame_gray, frame_gray)\n",
    "\n",
    "            if(is_static(similarity)):\n",
    "                newimg_thresh = mse(frame_gray, last_image_gray)\n",
    "\n",
    "                if(newimg_thresh >= MSE_NEW):\n",
    "                    valid_image = True\n",
    "\n",
    "                    if(newimg_thresh <= MSE_VALID):\n",
    "                        double_check = msssim(frame_gray, last_image_gray).real\n",
    "                        log_info = f'Image{num_slide}-{currentframe}-> {newimg_thresh:.2f}, {double_check:5f} msssim'\n",
    "                        if(double_check > MSSSIM_SAME):\n",
    "                            print('X ' + log_info)\n",
    "                            valid_image = False\n",
    "                        else:\n",
    "                            print(f'F ' + log_info)\n",
    "\n",
    "                    if(valid_image):\n",
    "                        valid_image, bw = check_bw_frame(frame_gray, currentframe)\n",
    "\n",
    "                    if(valid_image):\n",
    "                        print(f'Image{num_slide}-{currentframe} -> {newimg_thresh:.2f}, {bw}')\n",
    "                        save_image(video_name, frame, num_slide, currentframe)\n",
    "                        num_slide += 1\n",
    "                    \n",
    "                    last_image_gray = frame_gray\n",
    "                        \n",
    "            last_frame_gray = frame_gray\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Video: What kinds of problems can it solve_.mp4\n",
    "* Frame: 4500 (same)\n",
    "    * mse: 5.704356\t\n",
    "    * msssim: 0.999670\n",
    "* Frame: 8358 (little diff)\n",
    "    * mse: 4.548090\n",
    "    * msssim: 0.997047\n",
    "* Frame: 8591 (little diff)\n",
    "    * 4.0318262924382715\n",
    "\n",
    "Results research\n",
    "* same_image -> msssim = 1, msssim >= 0.999670\n",
    "* min_change -> 0.997047\n",
    "\n",
    "* Infuse your apps with ML\n",
    "* Image3-403 -> 0.998119 msssim (same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"What kinds of problems can it solve_.mp4\"\n",
    "imgs_idx = [0, 167, 511, 1309, 1383, 1590, 1791, 1896, 2791, 3502, 4466, 4500, 5045, 5978, 6754, 7397, 8035, 8358, 8668, 8866]\n",
    "# test_metrics = ['mse', 'rmse', 'psnr', 'uqi', 'ergas', 'scc', 'rase', 'sam', 'msssim', 'vifp', 'psnrb']\n",
    "test_metrics = ['ssim']\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "_, last_frame = cam.read()\n",
    "last_image = last_frame\n",
    "currentframe = 1\n",
    "\n",
    "data = {'img': imgs_idx[1:]}\n",
    "\n",
    "for metric in test_metrics:\n",
    "    data[metric] = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_image_gray = cv2.cvtColor(last_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            for metric in test_metrics:\n",
    "                if metric == 'msssim':\n",
    "                    data[metric].append(metrics[metric](frame_gray, last_image_gray).real)\n",
    "                else:\n",
    "                    data[metric].append(metrics[metric](frame_gray, last_image_gray))\n",
    "            \n",
    "            last_image = frame\n",
    "            \n",
    "        currentframe += 1\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"Course introduction.mp4\"\n",
    "imgs_idx = [0, 139, 267, 314, 459, 585, 713, 794, 938, 1500]\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "_, last_frame = cam.read()\n",
    "last_image = last_frame\n",
    "currentframe = 1\n",
    "\n",
    "sim_mse = []\n",
    "newimg_mse = []\n",
    "sim_msssim = []\n",
    "newimg_msssim = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_frame_gray = cv2.cvtColor(last_frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_image_gray = cv2.cvtColor(last_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # sim_mse.append(mse(last_frame_gray, frame_gray))\n",
    "            # newimg_mse.append(mse(frame_gray, last_image_gray))\n",
    "            sim_msssim.append(msssim(last_frame_gray, frame_gray).real)\n",
    "            newimg_msssim.append(msssim(frame_gray, last_image_gray).real)\n",
    "            \n",
    "            last_image = frame\n",
    "            \n",
    "        currentframe += 1\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'img': imgs_idx[1:],\n",
    "    # 'sim_mse': sim_mse,\n",
    "    # 'newimg_mse': newimg_mse,\n",
    "    'sim_msssim': sim_msssim,\n",
    "    'newimg_msssim': newimg_msssim\n",
    "})\n",
    "\n",
    "cam.release()\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing two pairs of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(video_name)\n",
    "\n",
    "imgs_idx = [4438, 4500, 8035, 8358]\n",
    "imgs = {}\n",
    "currentframe = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            imgs[currentframe] = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        currentframe += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp1_2 = []\n",
    "comp3_4 = []\n",
    "\n",
    "for metr in metrics:\n",
    "    comp1_2.append(metr(imgs[imgs_idx[0]], imgs[imgs_idx[1]]))\n",
    "    comp3_4.append(metr(imgs[imgs_idx[2]], imgs[imgs_idx[3]]))\n",
    "\n",
    "data = pd.DataFrame({'metric': metrics.keys(), 'comp1_2': comp1_2, 'comp3_4':comp3_4})\n",
    "data['good'] = data['comp1_2'] > data['comp3_4']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frames similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(\"Course introduction.mp4\")\n",
    "_, last_frame = cam.read()\n",
    "\n",
    "similarity_all = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        similarity_all.append(mse(last_frame, frame))\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev_tf211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "032a79404451c8e544ed63ad22a7b921b77b02e0977aab28375371efbf6895a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
