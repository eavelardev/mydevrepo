{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sewar.full_ref import mse, rmse, psnr, rmse_sw, uqi, ssim, ergas, scc, rase, sam, msssim, vifp, psnrb \n",
    "metrics = {'mse':mse, 'rmse':rmse, 'psnr':psnr, 'rmse_sw':rmse_sw, 'uqi':uqi, 'ssim':ssim, \n",
    "    'ergas':ergas, 'scc':scc, 'rase':rase, 'sam': sam, 'msssim': msssim, 'vifp':vifp, 'psnrb':psnrb }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract images from video in Python\n",
    "\n",
    "https://www.geeksforgeeks.org/extract-images-from-video-in-python/\n",
    "\n",
    "OpenCV - Getting Started with Videos\n",
    "\n",
    "https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(frame, slide, num_frame):\n",
    "    name = f'./data/frame{slide}-{num_frame}.jpg'\n",
    "    cv2.imwrite(name, frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving images with thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image1-43 -> 29.62, 505846944\n",
      "Image2-113 -> 2321.23, 515480658\n",
      "Image3-323 -> 244.26, 512608784\n",
      "Image4-1243 -> 907.50, 502352879\n",
      "X Image5-1293-> 0.999503 msssim\n",
      "Image5-2623 -> 1996.52, 514232743\n",
      "Image6-3853 -> 407.91, 509383009\n",
      "Image7-4393 -> 1039.86, 522774524\n",
      "Image8-4973 -> 153.20, 521008401\n",
      "Image9-5243 -> 238.88, 518285969\n",
      "Image10-5653 -> 38.01, 517785626\n"
     ]
    }
   ],
   "source": [
    "video_name = \"Lab solutions_ Framing a machine learning problem\"\n",
    "\n",
    "MSE_SAME = 0.1\n",
    "MSE_NEW = 4\n",
    "MSE_VALID = 8\n",
    "MSSSIM_SAME = 0.999\n",
    "WHITE_FRAME = 528765071 \n",
    "BLACK_FRAME = 0\n",
    "NUM_FRAMES_CHECK_STATIC = 12 \n",
    "frame_step = 2\n",
    "\n",
    "def is_static(val):\n",
    "    return val < MSE_SAME\n",
    "\n",
    "def check_bw_frame(frame, idx):\n",
    "    bw_check = np.sum(frame)\n",
    "    valid_frame = True\n",
    "\n",
    "    if(bw_check >= WHITE_FRAME):\n",
    "        print(f'X Image{currentframe} -> white')\n",
    "        valid_frame = False\n",
    "    elif(bw_check <= 0):\n",
    "        print(f'X Image{currentframe} -> black')\n",
    "        valid_frame = False\n",
    "\n",
    "    return valid_frame, bw_check\n",
    "\n",
    "video_path = '/mnt/c/Users/Eduardo/Downloads/' + video_name + '.mp4'\n",
    "cam = cv2.VideoCapture(video_path)\n",
    "\n",
    "currentframe = 0\n",
    "num_slide = 1\n",
    "\n",
    "#### Check if video start static\n",
    "_, frame = cam.read()\n",
    "currentframe += 1\n",
    "last_frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "last_image_gray = last_frame_gray.copy()\n",
    "\n",
    "static_found = False\n",
    "\n",
    "while((static_found == False) and (currentframe < NUM_FRAMES_CHECK_STATIC)):\n",
    "    for  _ in range(frame_step):\n",
    "        ret, frame = cam.read()\n",
    "        currentframe += 1\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    similarity = mse(frame_gray, last_frame_gray)\n",
    "\n",
    "    if(is_static(similarity)):\n",
    "        valid_image, bw = check_bw_frame(last_image_gray, currentframe)\n",
    "\n",
    "        if(valid_image):\n",
    "            print(f'Image{currentframe} -> {bw}')\n",
    "            save_image(frame, num_slide, currentframe)\n",
    "            num_slide += 1\n",
    "\n",
    "        static_found = True\n",
    "\n",
    "    last_frame_gray = frame_gray.copy()\n",
    "    last_image_gray = frame_gray.copy()\n",
    "    \n",
    "#### end\n",
    "\n",
    "frame_step = 10\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    for  _ in range(frame_step):\n",
    "        ret, frame = cam.read()\n",
    "        currentframe += 1\n",
    "  \n",
    "    if ret:\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        similarity = mse(last_frame_gray, frame_gray)\n",
    "\n",
    "        if(is_static(similarity)):\n",
    "            newimg_thresh = mse(frame_gray, last_image_gray)\n",
    "\n",
    "            if(newimg_thresh > MSE_NEW):\n",
    "                valid_image = True\n",
    "\n",
    "                if(newimg_thresh < MSE_VALID):\n",
    "                    double_check = msssim(frame_gray, last_image_gray).real\n",
    "                    if(double_check > MSSSIM_SAME):\n",
    "                        print(f'X Image{num_slide}-{currentframe}-> {double_check:5f} msssim')\n",
    "                        valid_image = False\n",
    "\n",
    "                if(valid_image):\n",
    "                    valid_image, bw = check_bw_frame(frame_gray, currentframe)\n",
    "\n",
    "                if(valid_image):\n",
    "                    print(f'Image{num_slide}-{currentframe} -> {newimg_thresh:.2f}, {bw}')\n",
    "                    save_image(frame, num_slide, currentframe)\n",
    "                    num_slide += 1\n",
    "                \n",
    "                last_image_gray = frame_gray.copy()\n",
    "                    \n",
    "        last_frame_gray = frame_gray.copy()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Video: What kinds of problems can it solve_.mp4\n",
    "* Frame: 4500 (same)\n",
    "    * mse: 5.704356\t\n",
    "    * msssim: 0.999670\n",
    "* Frame: 8358 (little diff)\n",
    "    * mse: 4.548090\n",
    "    * msssim: 0.997047\n",
    "* Frame: 8591 (little diff)\n",
    "    * 4.0318262924382715\n",
    "\n",
    "Results research\n",
    "* same_image -> msssim = 1, msssim >= 0.999670\n",
    "* min_change -> 0.997047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"What kinds of problems can it solve_.mp4\"\n",
    "imgs_idx = [0, 167, 511, 1309, 1383, 1590, 1791, 1896, 2791, 3502, 4466, 4500, 5045, 5978, 6754, 7397, 8035, 8358, 8668, 8866]\n",
    "# test_metrics = ['mse', 'rmse', 'psnr', 'uqi', 'ergas', 'scc', 'rase', 'sam', 'msssim', 'vifp', 'psnrb']\n",
    "test_metrics = ['ssim']\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "_, last_frame = cam.read()\n",
    "last_image = last_frame\n",
    "currentframe = 1\n",
    "\n",
    "data = {'img': imgs_idx[1:]}\n",
    "\n",
    "for metric in test_metrics:\n",
    "    data[metric] = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_image_gray = cv2.cvtColor(last_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            for metric in test_metrics:\n",
    "                if metric == 'msssim':\n",
    "                    data[metric].append(metrics[metric](frame_gray, last_image_gray).real)\n",
    "                else:\n",
    "                    data[metric].append(metrics[metric](frame_gray, last_image_gray))\n",
    "            \n",
    "            last_image = frame\n",
    "            \n",
    "        currentframe += 1\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"Course introduction.mp4\"\n",
    "imgs_idx = [0, 139, 267, 314, 459, 585, 713, 794, 938, 1500]\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "_, last_frame = cam.read()\n",
    "last_image = last_frame\n",
    "currentframe = 1\n",
    "\n",
    "sim_mse = []\n",
    "newimg_mse = []\n",
    "sim_msssim = []\n",
    "newimg_msssim = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_frame_gray = cv2.cvtColor(last_frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_image_gray = cv2.cvtColor(last_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # sim_mse.append(mse(last_frame_gray, frame_gray))\n",
    "            # newimg_mse.append(mse(frame_gray, last_image_gray))\n",
    "            sim_msssim.append(msssim(last_frame_gray, frame_gray).real)\n",
    "            newimg_msssim.append(msssim(frame_gray, last_image_gray).real)\n",
    "            \n",
    "            last_image = frame\n",
    "            \n",
    "        currentframe += 1\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'img': imgs_idx[1:],\n",
    "    # 'sim_mse': sim_mse,\n",
    "    # 'newimg_mse': newimg_mse,\n",
    "    'sim_msssim': sim_msssim,\n",
    "    'newimg_msssim': newimg_msssim\n",
    "})\n",
    "\n",
    "cam.release()\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing two pairs of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(video_name)\n",
    "\n",
    "imgs_idx = [4438, 4500, 8035, 8358]\n",
    "imgs = {}\n",
    "currentframe = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            imgs[currentframe] = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        currentframe += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp1_2 = []\n",
    "comp3_4 = []\n",
    "\n",
    "for metr in metrics:\n",
    "    comp1_2.append(metr(imgs[imgs_idx[0]], imgs[imgs_idx[1]]))\n",
    "    comp3_4.append(metr(imgs[imgs_idx[2]], imgs[imgs_idx[3]]))\n",
    "\n",
    "data = pd.DataFrame({'metric': metrics.keys(), 'comp1_2': comp1_2, 'comp3_4':comp3_4})\n",
    "data['good'] = data['comp1_2'] > data['comp3_4']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frames similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(\"Course introduction.mp4\")\n",
    "_, last_frame = cam.read()\n",
    "\n",
    "similarity_all = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        similarity_all.append(mse(last_frame, frame))\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev_tf211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "032a79404451c8e544ed63ad22a7b921b77b02e0977aab28375371efbf6895a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
