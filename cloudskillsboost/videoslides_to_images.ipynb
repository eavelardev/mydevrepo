{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sewar.full_ref import mse, rmse, psnr, rmse_sw, uqi, ssim, ergas, scc, rase, sam, msssim, vifp, psnrb \n",
    "metrics = {'mse':mse, 'rmse':rmse, 'psnr':psnr, 'rmse_sw':rmse_sw, 'uqi':uqi, 'ssim':ssim, \n",
    "    'ergas':ergas, 'scc':scc, 'rase':rase, 'sam': sam, 'msssim': msssim, 'vifp':vifp, 'psnrb':psnrb }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract images from video in Python\n",
    "\n",
    "https://www.geeksforgeeks.org/extract-images-from-video-in-python/\n",
    "\n",
    "OpenCV - Getting Started with Videos\n",
    "\n",
    "https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(video_name, frame, slide, num_frame):\n",
    "    name = f'./data/{video_name}/frame{slide}-{num_frame}.jpg'\n",
    "    cv2.imwrite(name, frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving images with thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "When to stop model training\n",
      "\n",
      "Image3 -> 509587705\n",
      "Image2-767 -> 499.31, 503214296\n",
      "Image3-1773 -> 211.63, 499508664\n",
      "Image4-2707 -> 2318.11, 524711532\n",
      "Image5-3127 -> 1494.94, 508113222\n",
      "Image6-4153 -> 2963.71, 494316500\n",
      "Image7-5111 -> 2678.92, 526200563\n",
      "Image8-5521 -> 1446.04, 511397118\n",
      "Image9-6623 -> 2212.29, 507116534\n",
      "Image10-6915 -> 1948.23, 525106181\n",
      "Image11-7091 -> 298.88, 522109589\n"
     ]
    }
   ],
   "source": [
    "videos_name = [\n",
    "    # 'Introduction',\n",
    "    # 'Generalization and ML models',\n",
    "    'When to stop model training',\n",
    "    # 'Creating repeatable samples in BigQuery',\n",
    "    # 'Lecture lab_  TensorFlow Playground - Advanced',\n",
    "    # 'Confusion matrix',\n",
    "    # 'Introducing the course dataset',\n",
    "]\n",
    "\n",
    "MSE_SAME = 0.07 # 0.07 - 0.1\n",
    "SAMPLING_RATE = 0.1 # 0.05 - 0.14 seconds\n",
    "SAMPLING_CHK_TIME = 0.6\n",
    "\n",
    "MSE_NEW = 4\n",
    "MSE_VALID = 15.53\n",
    "MSSSIM_SAME = 0.998038\n",
    "# MSSSIM_SAME = 0.997781\n",
    "WHITE_FRAME = 528757248\n",
    "BLACK_FRAME = 2339\n",
    "\n",
    "def is_static(val):\n",
    "    return val < MSE_SAME\n",
    "\n",
    "\n",
    "def check_bw_frame(frame, idx):\n",
    "    bw_check = np.sum(frame)\n",
    "    valid_frame = True\n",
    "\n",
    "    if(bw_check >= WHITE_FRAME):\n",
    "        print(f'X Image{idx} -> white')\n",
    "        valid_frame = False\n",
    "    elif(bw_check <= BLACK_FRAME):\n",
    "        print(f'X Image{idx} -> black')\n",
    "        valid_frame = False\n",
    "\n",
    "    return valid_frame, bw_check\n",
    "\n",
    "\n",
    "for video_name in videos_name:\n",
    "\n",
    "    print(f'\\n{video_name}\\n')\n",
    "\n",
    "    if not os.path.exists(f'data/{video_name}'):\n",
    "        os.makedirs(f'data/{video_name}')\n",
    "    \n",
    "    video_path = f'/mnt/c/Users/Eduardo/Downloads/{video_name}.mp4'\n",
    "    cam = cv2.VideoCapture(video_path)\n",
    "\n",
    "    currentframe = 0\n",
    "    num_slide = 1\n",
    "\n",
    "    #### Check if video start static\n",
    "    _, frame = cam.read()\n",
    "    currentframe += 1\n",
    "    last_frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    last_image_gray = last_frame_gray\n",
    "\n",
    "    static_found = False\n",
    "\n",
    "    frame_step = round(SAMPLING_RATE * cam.get(cv2.CAP_PROP_FPS))\n",
    "    num_frames_chk = round(SAMPLING_CHK_TIME * cam.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    while((static_found == False) and (currentframe < num_frames_chk)):\n",
    "        for  _ in range(frame_step):\n",
    "            ret, frame = cam.read()\n",
    "            currentframe += 1\n",
    "\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        similarity = mse(frame_gray, last_frame_gray)\n",
    "\n",
    "        if(is_static(similarity)):\n",
    "            valid_image, bw = check_bw_frame(last_image_gray, currentframe)\n",
    "\n",
    "            if(valid_image):\n",
    "                print(f'Image{currentframe} -> {bw}')\n",
    "                save_image(video_name, frame, num_slide, currentframe)\n",
    "                num_slide += 1\n",
    "\n",
    "            static_found = True\n",
    "\n",
    "        last_frame_gray = frame_gray\n",
    "        last_image_gray = frame_gray\n",
    "        \n",
    "    #### end\n",
    "\n",
    "    while(True):\n",
    "        \n",
    "        for  _ in range(frame_step):\n",
    "            ret, frame = cam.read()\n",
    "            currentframe += 1\n",
    "    \n",
    "        if ret:\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            similarity = mse(last_frame_gray, frame_gray)\n",
    "\n",
    "            if(is_static(similarity)):\n",
    "                newimg_thresh = mse(frame_gray, last_image_gray)\n",
    "\n",
    "                if(newimg_thresh >= MSE_NEW):\n",
    "                    valid_image = True\n",
    "\n",
    "                    if(newimg_thresh <= MSE_VALID):\n",
    "                        double_check = msssim(frame_gray, last_image_gray).real\n",
    "                        log_info = f'Image{num_slide}-{currentframe}-> {newimg_thresh:.2f}, {double_check:5f} msssim'\n",
    "                        if(double_check > MSSSIM_SAME):\n",
    "                            print('X ' + log_info)\n",
    "                            valid_image = False\n",
    "                        else:\n",
    "                            print(f'F ' + log_info)\n",
    "\n",
    "                    if(valid_image):\n",
    "                        valid_image, bw = check_bw_frame(frame_gray, currentframe)\n",
    "\n",
    "                    if(valid_image):\n",
    "                        print(f'Image{num_slide}-{currentframe} -> {newimg_thresh:.2f}, {bw}')\n",
    "                        save_image(video_name, frame, num_slide, currentframe)\n",
    "                        num_slide += 1\n",
    "                    \n",
    "                    last_image_gray = frame_gray\n",
    "                        \n",
    "            last_frame_gray = frame_gray\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Video: What kinds of problems can it solve_.mp4\n",
    "* Frame: 4500 (same)\n",
    "    * mse: 5.704356\t\n",
    "    * msssim: 0.999670\n",
    "* Frame: 8358 (little diff)\n",
    "    * mse: 4.548090\n",
    "    * msssim: 0.997047\n",
    "* Frame: 8591 (little diff)\n",
    "    * 4.0318262924382715\n",
    "\n",
    "Results research\n",
    "* same_image -> msssim = 1, msssim >= 0.999670\n",
    "* min_change -> 0.997047\n",
    "\n",
    "* Infuse your apps with ML\n",
    "* Image3-403 -> 0.998119 msssim (same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"What kinds of problems can it solve_.mp4\"\n",
    "imgs_idx = [0, 167, 511, 1309, 1383, 1590, 1791, 1896, 2791, 3502, 4466, 4500, 5045, 5978, 6754, 7397, 8035, 8358, 8668, 8866]\n",
    "# test_metrics = ['mse', 'rmse', 'psnr', 'uqi', 'ergas', 'scc', 'rase', 'sam', 'msssim', 'vifp', 'psnrb']\n",
    "test_metrics = ['ssim']\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "_, last_frame = cam.read()\n",
    "last_image = last_frame\n",
    "currentframe = 1\n",
    "\n",
    "data = {'img': imgs_idx[1:]}\n",
    "\n",
    "for metric in test_metrics:\n",
    "    data[metric] = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_image_gray = cv2.cvtColor(last_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            for metric in test_metrics:\n",
    "                if metric == 'msssim':\n",
    "                    data[metric].append(metrics[metric](frame_gray, last_image_gray).real)\n",
    "                else:\n",
    "                    data[metric].append(metrics[metric](frame_gray, last_image_gray))\n",
    "            \n",
    "            last_image = frame\n",
    "            \n",
    "        currentframe += 1\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"Course introduction.mp4\"\n",
    "imgs_idx = [0, 139, 267, 314, 459, 585, 713, 794, 938, 1500]\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "_, last_frame = cam.read()\n",
    "last_image = last_frame\n",
    "currentframe = 1\n",
    "\n",
    "sim_mse = []\n",
    "newimg_mse = []\n",
    "sim_msssim = []\n",
    "newimg_msssim = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_frame_gray = cv2.cvtColor(last_frame, cv2.COLOR_BGR2GRAY)\n",
    "            last_image_gray = cv2.cvtColor(last_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # sim_mse.append(mse(last_frame_gray, frame_gray))\n",
    "            # newimg_mse.append(mse(frame_gray, last_image_gray))\n",
    "            sim_msssim.append(msssim(last_frame_gray, frame_gray).real)\n",
    "            newimg_msssim.append(msssim(frame_gray, last_image_gray).real)\n",
    "            \n",
    "            last_image = frame\n",
    "            \n",
    "        currentframe += 1\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'img': imgs_idx[1:],\n",
    "    # 'sim_mse': sim_mse,\n",
    "    # 'newimg_mse': newimg_mse,\n",
    "    'sim_msssim': sim_msssim,\n",
    "    'newimg_msssim': newimg_msssim\n",
    "})\n",
    "\n",
    "cam.release()\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing two pairs of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(video_name)\n",
    "\n",
    "imgs_idx = [4438, 4500, 8035, 8358]\n",
    "imgs = {}\n",
    "currentframe = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        if(currentframe in imgs_idx):\n",
    "            imgs[currentframe] = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        currentframe += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp1_2 = []\n",
    "comp3_4 = []\n",
    "\n",
    "for metr in metrics:\n",
    "    comp1_2.append(metr(imgs[imgs_idx[0]], imgs[imgs_idx[1]]))\n",
    "    comp3_4.append(metr(imgs[imgs_idx[2]], imgs[imgs_idx[3]]))\n",
    "\n",
    "data = pd.DataFrame({'metric': metrics.keys(), 'comp1_2': comp1_2, 'comp3_4':comp3_4})\n",
    "data['good'] = data['comp1_2'] > data['comp3_4']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frames similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(\"Course introduction.mp4\")\n",
    "_, last_frame = cam.read()\n",
    "\n",
    "similarity_all = []\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cam.read()\n",
    "  \n",
    "    if ret:\n",
    "        similarity_all.append(mse(last_frame, frame))\n",
    "        last_frame = frame\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev_tf211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "032a79404451c8e544ed63ad22a7b921b77b02e0977aab28375371efbf6895a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
