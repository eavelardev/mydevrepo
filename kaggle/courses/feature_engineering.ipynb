{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from category_encoders import MEstimateEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "    X[colname], _ = X[colname].factorize()\n",
    "\n",
    "# All discrete features should now have integer dtypes\n",
    "discrete_features = X.dtypes == int\n",
    "discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "mi_scores = mi_scores.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "\n",
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "plot_mi_scores(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"horsepower\", y=\"price\", hue=\"fuel_type\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"BldgType\", y=\"SalePrice\", data=df, kind=\"boxen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete[\"Components\"] = concrete[components].gt(0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer[[\"Type\", \"Level\"]] = (  # Create two new features\n",
    "    customer[\"Policy\"]           # from the Policy feature\n",
    "    .str                         # through the string accessor\n",
    "    .split(\" \", expand=True)     # by splitting on \" \"\n",
    "                                 # and expanding the result into separate columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer[\"AverageIncome\"] = (\n",
    "    customer.groupby(\"State\")  # for each state\n",
    "    [\"Income\"]                 # select the income\n",
    "    .transform(\"mean\")         # and compute its mean\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frequency with which each state occurs in the dataset\n",
    "\n",
    "customer[\"StateFreq\"] = (\n",
    "    customer.groupby(\"State\")\n",
    "    [\"State\"]\n",
    "    .transform(\"count\")\n",
    "    / customer.State.count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"AverageClaim\"] = df_train.groupby(\"Coverage\")[\"ClaimAmount\"].transform(\"mean\")\n",
    "\n",
    "# Merge the values into the validation set\n",
    "df_valid = df_valid.merge(\n",
    "    df_train[[\"Coverage\", \"AverageClaim\"]].drop_duplicates(),\n",
    "    on=\"Coverage\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = X.loc[:, features]\n",
    "X_scaled = (X_scaled - X_scaled.mean()) / X_scaled.std()\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, n_init=10, random_state=0)\n",
    "\n",
    "X_cd = kmeans.fit_transform(X_scaled)\n",
    "\n",
    "X_cd = pd.DataFrame(X_cd, columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])])\n",
    "X = X.join(X_cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(X, standardize=True):\n",
    "    # Standardize\n",
    "    if standardize:\n",
    "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Create principal components\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    # Convert to dataframe\n",
    "    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "    X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "    # Create loadings\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T,  # transpose the matrix of loadings\n",
    "        columns=component_names,  # so the columns are the principal components\n",
    "        index=X.columns,  # and the rows are the original features\n",
    "    )\n",
    "    return pca, X_pca, loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "        \n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    # Label encoding for categoricals\n",
    "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    score = cross_val_score(\n",
    "        model, X, y, cv=5, scoring=\"neg_mean_squared_log_error\",\n",
    "    )\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop('Rating')\n",
    "\n",
    "X_encode = X.sample(frac=0.25)\n",
    "y_encode = y[X_encode.index]\n",
    "X_pretrain = X.drop(X_encode.index)\n",
    "y_train = y[X_pretrain.index]\n",
    "\n",
    "# Create the encoder instance. Choose m to control noise.\n",
    "encoder = MEstimateEncoder(cols=[\"Zipcode\"], m=5.0)\n",
    "\n",
    "# Fit the encoder on the encoding split.\n",
    "encoder.fit(X_encode, y_encode)\n",
    "\n",
    "# Encode the Zipcode column to create the final training data\n",
    "X_train = encoder.transform(X_pretrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_cert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdc61549ca29cf556f83ccb966c26ebc085b6ed141d6cc6c04c04aafef5b7244"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
