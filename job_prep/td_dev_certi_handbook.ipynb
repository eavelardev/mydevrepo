{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Developer Certificate\n",
    "**Web:** : [www.tensorflow.org/certificate](https://www.tensorflow.org/certificate)\n",
    "\n",
    "Candidate Handbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TF_Certificate_Candidate_Handbook.pdf](https://www.tensorflow.org/extras/cert/TF_Certificate_Candidate_Handbook.pdf)\n",
    "\n",
    "Last Updated: August 12, 2021\n",
    "\n",
    "[Setting_Up_TF_Developer_Certificate_Exam.pdf](https://www.tensorflow.org/extras/cert/Setting_Up_TF_Developer_Certificate_Exam.pdf)\n",
    "\n",
    "Last Updated: July 12 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice training TensorFlow models\n",
    "* [Image classification](https://www.tensorflow.org/tutorials/images/classification)\n",
    "* [Word embeddings](https://www.tensorflow.org/text/guide/word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skills checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) TensorFlow developer skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Know how to program in Python, resolve Python issues, and compile and run Python programs\n",
    "in PyCharm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Know how to find information about TensorFlow APIs, including how to find guides and API\n",
    "references on tensorflow.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Know how to debug, investigate, and solve error messages from the TensorFlow API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Know how to search beyond tensorflow.org, as and when necessary, to solve your TensorFlow\n",
    "questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Know how to create ML models using TensorFlow where the model size is reasonable for the\n",
    "problem being solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "inputs = layers.Input(shape=(...))\n",
    "x = ...(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs, x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x Know how to save ML models and check the model file size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.save('my_model.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Understand the compatibility discrepancies between different versions of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Building and training neural network models using TensorFlow 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use TensorFlow 2.x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Build, compile and train machine learning (ML) models using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber loss is less sensitive to outliers in data than squared-error loss.\n",
    "Huber Loss minimize sensitivity to outliers.\n",
    "Huber is used for time series.\n",
    "\n",
    "```python\n",
    "model.compile(optimizer=<>,\n",
    "              loss=<>,\n",
    "              metrics=['<>'])\n",
    "\n",
    "history = model.fit(x, y)\n",
    "history = model.fit(dataset, epochs=<>, steps_per_epoch=<>)\n",
    "\n",
    "loss, accuracy = model.evaluate(x, y)\n",
    "loss, accuracy = model.evaluate(dataset)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Preprocess data to get it ready for use in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# or\n",
    "\n",
    "layers.Rescaling(1/255, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "def reshape_and_normalize(images):\n",
    "    images = np.expand_dims(images, axis=-1) # for Conv\n",
    "    images = images / 255.\n",
    "    return images\n",
    "\n",
    "# Time Series\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n",
    "df_std = (df - train_mean) / train_std\n",
    "\n",
    "wv = df['wv (m/s)']\n",
    "wv[wv == -9999.0] = 0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use models to predict results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "predictions = model.predict(x)\n",
    "\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "predictions = tf.nn.softmax(predictions)\n",
    "predictions = [class_names[np.argmax(prediction) for prediction in predictions]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Build sequential models with multiple layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    layers.<>(..., input_shape=<>),\n",
    "    layers.<>(...)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Build and train models for binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 2 classes\n",
    "layers.Dense(1) # Output\n",
    "model.compile(optimizer=<>,\n",
    "              loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['<>'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Build and train models for multi-class categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# n classes\n",
    "layers.Dense(n) # Output\n",
    "model.compile(optimizer=<>,\n",
    "                loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['<>'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Plot loss and accuracy of a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training y Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training loss')\n",
    "    plt.plot(val_loss, label='Validation loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Trainind and Validation Loss')\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Identify strategies to prevent overfitting, including augmentation and dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use pretrained models (transfer learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(...),\n",
    "                                               include_top=False)\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "inputs = layers.Input(shape=(...))\n",
    "# x = data_augmentation(inputs)\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "# x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "fine_tune_at = 100\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Extract features from pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Ensure that inputs to a model are in the correct shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Ensure that you can match test data to the input shape of a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Ensure you can match output data of a neural network to specified input shape for test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Understand batch loading of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use callbacks to trigger the end of training cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs['accuracy'] > <>):\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "    keras.callbacks.ModelCheckpoint(\"tfmodel.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(..., callbacks=[callbacks])\n",
    "\n",
    "model = tf.keras.models.load_model(\"tfmodel.h5\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use datasets from different sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dataset_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "dataset_file = tf.keras.utils.get_file('cat_and_dogs.zip', origin=dataset_url, extract=True)\n",
    "data_path = os.path.join(os.path.dirname(dataset_file), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(data_path, 'train')\n",
    "...\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use datasets in different formats, including json and csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "def parse_data_from_file(filename):\n",
    "\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            sentences.append(row[1])\n",
    "            labels.append(row[0])\n",
    "\n",
    "    return sentences, labels\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use datasets from `tf.data.datasets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Define Convolutional neural networks with `Conv2D` and `pooling layers`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(),\n",
    "    ...\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Build and train models to process real-world image datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Understand how to use convolutions to improve your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use real-world images in different shapes and sizes.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use `image augmentation` to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomRotation(0.2)\n",
    "])\n",
    "\n",
    "inputs = layers.Input(shape=<>)\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "...\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use `ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory=base_dir,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=10,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    label_mode='binary',\n",
    "    batch_size=10,\n",
    "    image_size=(150, 150)\n",
    ").cache().prefetch(tf.data.AUTOTUNE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Understand how ImageDataGenerator labels images based on the directory structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Natural language processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Build natural language processing systems using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Prepare text to use in TensorFlow models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def custom_standardization(input_data):\n",
    "    text = tf.strings.lower(input_data)\n",
    "    text = tf.strings.regex_replace(text, '<br />', ' ')\n",
    "    text = tf.strings.regex_replace(text, '[%s]' % re.escape(string.punctuation), ' ')\n",
    "    # Remove non-ASCII characters\n",
    "    text = tf.strings.regex_replace(text, r'[^\\x00-\\x7F]+', ' ')\n",
    "    for word in stopwords:\n",
    "        text = tf.strings.regex_replace(text, rf'\\b{word}\\b', '')\n",
    "    return text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Build models that identify the category of a piece of text using `binary categorization`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Build models that identify the category of a piece of text using `multi-class categorization`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use `word embeddings` in your TensorFlow model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use `LSTMs` in your model to classify text for either `binary` or `multi-class categorization`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Add `RNN` and `GRU` layers to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use `RNNS`, `LSTMs`, `GRUs` and `CNNs` in models that work with text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Train `LSTMs` on existing text to `generate text` (such as songs and poetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Time series, sequences and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] `Train`, `tune` and use `time series`, `sequence` and `prediction models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Train models to predict values for both `univariate` and `multivariate time series`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] `Prepare data` for `time series` learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Understand `Mean Absolute Error (MAE)` and how it can be used to evaluate accuracy of\n",
    "sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use `RNNs` and `CNNs` for `time series`, `sequence` and `forecasting models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Identify when to use `trailing` versus `centred windows`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Use `TensorFlow for forecasting`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] `Prepare features` and `labels`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
    "\n",
    "delay = None\n",
    "data = df[:-delay]\n",
    "targets = temperature[delay:],\n",
    "\n",
    "train_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data, targets, sequence_length,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Identify and compensate for `sequence bias`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should put a number equal or greater than the total number of elements for better shuffling\n",
    "\n",
    "```python\n",
    "dataset = dataset.shuffle(buffer_size=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] `Adjust the learning rate dynamically` in `time series`, `sequence` and `prediction models`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dbb6e28f32ca2376e4f57c81cef85cf88ffd88cbd1c487658c99f00bdea0c93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
