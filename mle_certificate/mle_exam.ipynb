{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from questions import questions\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total questions: 221\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of total questions: {len(questions)}')\n",
    "questions = random.sample(questions, len(questions))\n",
    "# questions = [q for q in questions if 'udemy' in q['tags']]\n",
    "# print(f'Number of questions: {len(questions)}')\n",
    "i = -1\n",
    "c = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs = [q['question'] for q in questions if len(q['question']) > 0]\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# keywords = {q: set(tokenizer.tokenize(q)) for q in qs}\n",
    "\n",
    "# scores = []\n",
    "# file1 = []\n",
    "# file2 = []\n",
    "\n",
    "# for i in range(len(keywords)-1):\n",
    "#     for j in range(i+1, len(keywords)):\n",
    "#         keyword1, keyword2 = keywords[qs[i]], keywords[qs[j]]\n",
    "#         intersect = len(keyword1.intersection(keyword2))\n",
    "#         min_set = min(len(keyword1), len(keyword2))\n",
    "#         rate = round(intersect / min_set, 2)\n",
    "        \n",
    "#         scores.append(rate)\n",
    "#         file1.append(qs[i])\n",
    "#         file2.append(qs[j])\n",
    "\n",
    "# data = {'score': scores, 'file1': file1, 'file2': file2}\n",
    "# df = pd.DataFrame(data).sort_values(by=['score', 'file1'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question(i):\n",
    "    i += 1\n",
    "    i %= len(questions)\n",
    "    question = questions[i]\n",
    "    print(question['question'], end='\\n')\n",
    "\n",
    "    options = random.sample(list(question['options'].values()), len(question['options']))\n",
    "    # options = question['options'].values()\n",
    "    \n",
    "    for option in options:\n",
    "        print(f'\\n* {option}')\n",
    "\n",
    "    return i, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(i, c):\n",
    "    if c is False:\n",
    "        question = questions[i]\n",
    "        if(len(question['answers']) > 0):\n",
    "            answers = random.sample(question['answers'], len(question['answers']))\n",
    "\n",
    "            for letter in answers:\n",
    "                answer = question['options'][letter]\n",
    "                print(f'* {answer}\\n')   \n",
    "\n",
    "            if question['explanation']:\n",
    "                print(question['explanation'] + '\\n') \n",
    "\n",
    "            for reference in question['references']:\n",
    "                print(f'* {reference}')\n",
    "        else:\n",
    "            print('No answer')\n",
    "    else:\n",
    "        print('')\n",
    "    c = not c\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You work for a video game company. Your management came up with the idea of creating a game in which the characteristics of the characters were taken from those of the human players. You have been asked to generate not only the avatars but also various visual expressions during the game actions.\n",
      "\n",
      "* Recurrent Neural Network\n",
      "\n",
      "* Reinforcement Learning\n",
      "\n",
      "* Convolutional Neural Network\n",
      "\n",
      "* Autoencoder and self-encoder\n",
      "\n",
      "* Feedforward Neural Network\n",
      "\n",
      "* GAN Generative Adversarial Network\n",
      "\n",
      "* Transformers\n"
     ]
    }
   ],
   "source": [
    "i, c = get_question(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* GAN Generative Adversarial Network\n",
      "\n",
      "GAN is a special class of machine learning frameworks used for the automatic generation of facial images.\n",
      "GAN can create new characters from the provided images.\n",
      "It is also used with photographs and can generate new photos that look authentic.\n",
      "It is a kind of model highly specialized for this task. So, it is the best solution.\n",
      "* Feedforward neural networks are the classic example of neural networks. In fact, they were the first and most elementary type of artificial neural network.\n",
      "Feedforward neural networks are mainly used for supervised learning when the data, mainly numerical, to be learned is neither time-series nor sequential (such as NLP).\n",
      "* The convolutional neural network (CNN) is a type of artificial neural network extensively used for image recognition and classification. It uses the convolutional layers, that is, the reworking of sets of pixels by running filters on the input pixels.\n",
      "* A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence.\n",
      "* A transformer is a deep learning model that can give different importance to each part of the input data.\n",
      "* Reinforcement Learning provides a software agent that evaluates possible solutions through a progressive reward in repeated attempts. It does not need to provide labels. But it requires a lot of data and several trials, and the possibility to evaluate the validity of each attempt.\n",
      "* Autoencoder is a neural network aimed to transform and learn with a compressed representation of raw data.\n",
      "\n",
      "* https://en.wikipedia.org/wiki/Generative_adversarial_network\n",
      "* https://developer.nvidia.com/blog/photo-editing-generative-adversarial-networks-2/\n"
     ]
    }
   ],
   "source": [
    "c = get_answers(i, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dbb6e28f32ca2376e4f57c81cef85cf88ffd88cbd1c487658c99f00bdea0c93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
