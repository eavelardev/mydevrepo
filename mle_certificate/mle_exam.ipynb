{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from questions import questions\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total questions: 235\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of total questions: {len(questions)}')\n",
    "questions = random.sample(questions, len(questions))\n",
    "# questions = [q for q in questions if 'udemy' in q['tags']]\n",
    "# print(f'Number of questions: {len(questions)}')\n",
    "i = -1\n",
    "c = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs = [q['question'] for q in questions if len(q['question']) > 0]\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# keywords = {q: set(tokenizer.tokenize(q)) for q in qs}\n",
    "\n",
    "# scores = []\n",
    "# file1 = []\n",
    "# file2 = []\n",
    "\n",
    "# for i in range(len(keywords)-1):\n",
    "#     for j in range(i+1, len(keywords)):\n",
    "#         keyword1, keyword2 = keywords[qs[i]], keywords[qs[j]]\n",
    "#         intersect = len(keyword1.intersection(keyword2))\n",
    "#         min_set = min(len(keyword1), len(keyword2))\n",
    "#         rate = round(intersect / min_set, 2)\n",
    "        \n",
    "#         scores.append(rate)\n",
    "#         file1.append(qs[i])\n",
    "#         file2.append(qs[j])\n",
    "\n",
    "# data = {'score': scores, 'file1': file1, 'file2': file2}\n",
    "# df = pd.DataFrame(data).sort_values(by=['score', 'file1'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question(i):\n",
    "    i += 1\n",
    "    i %= len(questions)\n",
    "    question = questions[i]\n",
    "    print(question['question'], end='\\n')\n",
    "\n",
    "    options = random.sample(list(question['options'].values()), len(question['options']))\n",
    "    # options = question['options'].values()\n",
    "    \n",
    "    for option in options:\n",
    "        print(f'\\n* {option}')\n",
    "\n",
    "    return i, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(i, c):\n",
    "    if c is False:\n",
    "        question = questions[i]\n",
    "        # if(len(question['answers']) > 0):\n",
    "        answers = random.sample(question['answers'], len(question['answers']))\n",
    "\n",
    "        for letter in answers:\n",
    "            answer = question['options'][letter]\n",
    "            print(f'* {answer}\\n')   \n",
    "\n",
    "        if question['explanation']:\n",
    "            print(question['explanation'] + '\\n') \n",
    "\n",
    "        for reference in question['references']:\n",
    "            print(f'* {reference}')\n",
    "        # else:\n",
    "        #     print('No answer')\n",
    "    else:\n",
    "        print('')\n",
    "    c = not c\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your company runs a big retail website. You develop many ML models for all the business activities.\n",
      "You migrated to Google Cloud. Your models are developed with PyTorch, TensorFlow and BigQueryML.\n",
      "You are now working on an international project with other partners.\n",
      "You need to let them use your Vertex AI dataset in Cloud Storage for a different organization.\n",
      "What can you do?\n",
      "\n",
      "* Exporting metadata and annotations in a CSV file\n",
      "\n",
      "* Copy the data in a removable storage\n",
      "\n",
      "* Give access (Service account or signed URL) to the Cloud Storage file\n",
      "\n",
      "* Let them use your GCP Account\n",
      "\n",
      "* Exporting metadata and annotations in a JSONL file\n"
     ]
    }
   ],
   "source": [
    "i, c = get_question(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Exporting metadata and annotations in a JSONL file\n",
      "\n",
      "* Give access (Service account or signed URL) to the Cloud Storage file\n",
      "\n",
      "You can export a Dataset; when you do that, no additional copies of data are generated. The result is only JSONL files with all the useful information, including the Cloud Storage files URIs.\n",
      "But you have to grant access to these  Cloud Storage files with a Service account or a signed URL, if to be used outside GCP.\n",
      "* Let them use your GCP Account, Copy the data in a removable storage are wrong mainly for security reasons.\n",
      "* Annotations are written in JSON files.\n",
      "\n",
      "* https://cloud.google.com/vertex-ai/docs/datasets/export-metadata-annotations\n",
      "* https://cloud.google.com/vertex-ai/docs/datasets/datasets\n",
      "* https://codelabs.developers.google.com/codelabs/vertex-ai-custom-code-training\n"
     ]
    }
   ],
   "source": [
    "c = get_answers(i, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dbb6e28f32ca2376e4f57c81cef85cf88ffd88cbd1c487658c99f00bdea0c93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
