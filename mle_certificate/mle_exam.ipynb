{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from questions import questions\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total questions: 241\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of total questions: {len(questions)}')\n",
    "questions = random.sample(questions, len(questions))\n",
    "# questions = [q for q in questions if 'udemy' in q['tags']]\n",
    "# print(f'Number of questions: {len(questions)}')\n",
    "i = -1\n",
    "c = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs = [q['question'] for q in questions if len(q['question']) > 0]\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# keywords = {q: set(tokenizer.tokenize(q)) for q in qs}\n",
    "\n",
    "# scores = []\n",
    "# file1 = []\n",
    "# file2 = []\n",
    "\n",
    "# for i in range(len(keywords)-1):\n",
    "#     for j in range(i+1, len(keywords)):\n",
    "#         keyword1, keyword2 = keywords[qs[i]], keywords[qs[j]]\n",
    "#         intersect = len(keyword1.intersection(keyword2))\n",
    "#         min_set = min(len(keyword1), len(keyword2))\n",
    "#         rate = round(intersect / min_set, 2)\n",
    "        \n",
    "#         scores.append(rate)\n",
    "#         file1.append(qs[i])\n",
    "#         file2.append(qs[j])\n",
    "\n",
    "# data = {'score': scores, 'file1': file1, 'file2': file2}\n",
    "# df = pd.DataFrame(data).sort_values(by=['score', 'file1'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question(i):\n",
    "    i += 1\n",
    "    i %= len(questions)\n",
    "    question = questions[i]\n",
    "    print(question['question'], end='\\n')\n",
    "\n",
    "    options = random.sample(list(question['options'].values()), len(question['options']))\n",
    "    # options = question['options'].values()\n",
    "    \n",
    "    for option in options:\n",
    "        print(f'\\n* {option}')\n",
    "\n",
    "    return i, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(i, c):\n",
    "    if c is False:\n",
    "        question = questions[i]\n",
    "        # if(len(question['answers']) > 0):\n",
    "        answers = random.sample(question['answers'], len(question['answers']))\n",
    "\n",
    "        for letter in answers:\n",
    "            answer = question['options'][letter]\n",
    "            print(f'* {answer}\\n')   \n",
    "\n",
    "        if question['explanation']:\n",
    "            print(question['explanation'] + '\\n') \n",
    "\n",
    "        for reference in question['references']:\n",
    "            print(f'* {reference}')\n",
    "        # else:\n",
    "        #     print('No answer')\n",
    "    else:\n",
    "        print('')\n",
    "    c = not c\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You developed a model for a classification task where the minority class appears in 10% of the data set. You ran the training on the original imbalanced data set and have checked the resulting model performance. The confusion matrix indicates that the model did not learn the minority class. You want to improve the model performance while minimizing run time and keeping the predictions calibrated. What should you do?\n",
      "\n",
      "* Tune the classification threshold, and calibrate the model with isotonic regression on the validation set.\n",
      "\n",
      "* Downsample the majority class in the training set, and update the weight of the downsampled class by the same sampling factor.\n",
      "\n",
      "* Upsample the minority class in the training set, and update the weight of the upsampled class by the same sampling factor.\n",
      "\n",
      "* Update the weights of the classification function to penalize misclassifications of the minority class.\n"
     ]
    }
   ],
   "source": [
    "i, c = get_question(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Downsample the majority class in the training set, and update the weight of the downsampled class by the same sampling factor.\n",
      "\n",
      "* Downsampling with upweighting improves performance on the minority class while speeding up convergence and keeping the predictions calibrated.\n",
      "* This approach does not guarantee calibrated predictions and does not improve training run time.\n",
      "* This approach increases run time by adding threshold tuning and calibration on top of model training.\n",
      "* Upsampling increases training run time by providing more data samples during training.\n",
      "\n",
      "* https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data\n",
      "* https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb\n",
      "* https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/calibration/calibration-node-classification.ipynb\n",
      "* https://developers.google.com/machine-learning/glossary#calibration-layer\n"
     ]
    }
   ],
   "source": [
    "c = get_answers(i, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dbb6e28f32ca2376e4f57c81cef85cf88ffd88cbd1c487658c99f00bdea0c93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
